using down sampling
using up sampling
================================================================================
SVC(C=5.2, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='ignore',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=True, max_df=1.0, max_features=None, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words='english',
       ...,
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False))])
================================================================================
             precision    recall  f1-score   support

    AGAINST     0.8182    0.8780    0.8471        82
      FAVOR     0.6686    0.6882    0.6782      1023
       NONE     0.7367    0.7155    0.7259      1255

avg / total     0.7100    0.7093    0.7095      2360

macro-average of F-score(FAVOR), F-score(AGAINST) and F-score(NONE): 0.7504

================================================================================
Validation score
================================================================================
             precision    recall  f1-score   support

    AGAINST     1.0000    0.1765    0.3000        17
      FAVOR     0.6542    0.6385    0.6463       877
       NONE     0.8228    0.8388    0.8307      1793

avg / total     0.7689    0.7693    0.7672      2687

Validation macro F-score: 0.5923

================================================================================
TEST RESULTS FOR
LinearSVC(C=1.178, class_weight=None, dual=True, fit_intercept=True,
     intercept_scaling=1, loss='squared_hinge', max_iter=1000,
     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
     verbose=0)
================================================================================
             precision    recall  f1-score   support

    AGAINST     0.5000    0.2105    0.2963        19
      FAVOR     0.6365    0.7163    0.6741       973
       NONE     0.8500    0.8026    0.8256      1991

avg / total     0.7781    0.7707    0.7728      2983

Test macro F-score: 0.5987
time =  119.126997948



using down sampling
================================================================================
SVC(C=5.2, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='ignore',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=True, max_df=1.0, max_features=None, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words='english',
       ...,
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False))])
================================================================================
             precision    recall  f1-score   support

    AGAINST     0.4348    0.2439    0.3125        41
      FAVOR     0.6705    0.6804    0.6754      1023
       NONE     0.7297    0.7315    0.7306      1255

avg / total     0.6984    0.7003    0.6989      2319

macro-average of F-score(FAVOR), F-score(AGAINST) and F-score(NONE): 0.5728

================================================================================
Validation score
================================================================================
             precision    recall  f1-score   support

    AGAINST     1.0000    0.1765    0.3000        17
      FAVOR     0.6542    0.6385    0.6463       877
       NONE     0.8228    0.8388    0.8307      1793

avg / total     0.7689    0.7693    0.7672      2687

Validation macro F-score: 0.5923


time =  142.55870986


testing with down sampling (SEPARATE RUN; NOT RELATED TO TRAIN/VAL)
================================================================================
TEST RESULTS FOR
LinearSVC(C=1.178, class_weight=None, dual=True, fit_intercept=True,
     intercept_scaling=1, loss='squared_hinge', max_iter=1000,
     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
     verbose=0)
================================================================================
             precision    recall  f1-score   support

    AGAINST     0.5000    0.2105    0.2963        19
      FAVOR     0.6365    0.7163    0.6741       973
       NONE     0.8500    0.8026    0.8256      1991

avg / total     0.7781    0.7707    0.7728      2983

Test macro F-score: 0.5987
time =  161.145936012



using up sampling
================================================================================
SVC(C=5.2, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='ignore',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=True, max_df=1.0, max_features=None, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words='english',
       ...,
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False))])
================================================================================
             precision    recall  f1-score   support

    AGAINST     0.8861    0.8537    0.8696        82
      FAVOR     0.6313    0.6051    0.6179      2046
       NONE     0.8096    0.8267    0.8181      4183

avg / total     0.7528    0.7552    0.7539      6311

macro-average of F-score(FAVOR), F-score(AGAINST) and F-score(NONE): 0.7685

================================================================================
Validation score
================================================================================
             precision    recall  f1-score   support

    AGAINST     1.0000    0.1765    0.3000        17
      FAVOR     0.6542    0.6385    0.6463       877
       NONE     0.8228    0.8388    0.8307      1793

avg / total     0.7689    0.7693    0.7672      2687

Validation macro F-score: 0.5923


time =  175.217615128


testing with up sampling
================================================================================
TEST RESULTS FOR
LinearSVC(C=1.178, class_weight=None, dual=True, fit_intercept=True,
     intercept_scaling=1, loss='squared_hinge', max_iter=1000,
     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
     verbose=0)
================================================================================
             precision    recall  f1-score   support

    AGAINST     0.5000    0.1053    0.1739        19
      FAVOR     0.7108    0.6238    0.6645       973
       NONE     0.8245    0.8800    0.8513      1991

avg / total     0.7853    0.7915    0.7861      2983

Test macro F-score: 0.5632
time =  317.268763065








#######################################
Multinomial NB
#######################################

using down sampling
using up sampling
================================================================================
MultinomialNB(alpha=0.1, class_prior=None, fit_prior=False)
================================================================================
             precision    recall  f1-score   support

    AGAINST     0.9600    0.8780    0.9172        82
      FAVOR     0.6636    0.7830    0.7184      1023
       NONE     0.7922    0.6805    0.7321      1255

avg / total     0.7423    0.7318    0.7326      2360

macro-average of F-score(FAVOR), F-score(AGAINST) and F-score(NONE): 0.7892

================================================================================
Validation score
================================================================================
             precision    recall  f1-score   support

    AGAINST     0.0000    0.0000    0.0000        17
      FAVOR     0.6162    0.7047    0.6574       877
       NONE     0.8414    0.7903    0.8151      1793

avg / total     0.7626    0.7574    0.7585      2687

Validation macro F-score: 0.4908

testing with down sampling
testing with up sampling
================================================================================
TEST RESULTS FOR
MultinomialNB(alpha=0.1, class_prior=None, fit_prior=False)
================================================================================
             precision    recall  f1-score   support

    AGAINST     0.3333    0.3158    0.3243        19
      FAVOR     0.5935    0.7698    0.6702       973
       NONE     0.8673    0.7418    0.7997      1991

avg / total     0.7746    0.7482    0.7544      2983

Test macro F-score: 0.5981
time =  92.7744238377


using down sampling
================================================================================
MultinomialNB(alpha=0.1, class_prior=None, fit_prior=False)
================================================================================
             precision    recall  f1-score   support

    AGAINST     0.0000    0.0000    0.0000        41
      FAVOR     0.6553    0.7713    0.7086      1023
       NONE     0.7731    0.6869    0.7274      1255

avg / total     0.7075    0.7119    0.7062      2319

macro-average of F-score(FAVOR), F-score(AGAINST) and F-score(NONE): 0.4787

================================================================================
Validation score
================================================================================
             precision    recall  f1-score   support

    AGAINST     0.0000    0.0000    0.0000        17
      FAVOR     0.6162    0.7047    0.6574       877
       NONE     0.8414    0.7903    0.8151      1793

avg / total     0.7626    0.7574    0.7585      2687

Validation macro F-score: 0.4908


testing with down sampling
================================================================================
TEST RESULTS FOR
MultinomialNB(alpha=0.1, class_prior=None, fit_prior=False)
================================================================================
             precision    recall  f1-score   support

    AGAINST     0.4000    0.1053    0.1667        19
      FAVOR     0.5886    0.7749    0.6690       973
       NONE     0.8674    0.7393    0.7983      1991

avg / total     0.7735    0.7469    0.7521      2983

Test macro F-score: 0.5447
time =  98.0226840973


using up sampling
================================================================================
MultinomialNB(alpha=0.1, class_prior=None, fit_prior=False)
================================================================================
             precision    recall  f1-score   support

    AGAINST     0.8889    0.8780    0.8834        82
      FAVOR     0.5901    0.7522    0.6614      2046
       NONE     0.8589    0.7437    0.7972      4183

avg / total     0.7722    0.7482    0.7543      6311

macro-average of F-score(FAVOR), F-score(AGAINST) and F-score(NONE): 0.7807

================================================================================
Validation score
================================================================================
             precision    recall  f1-score   support

    AGAINST     0.0000    0.0000    0.0000        17
      FAVOR     0.6162    0.7047    0.6574       877
       NONE     0.8414    0.7903    0.8151      1793

avg / total     0.7626    0.7574    0.7585      2687

Validation macro F-score: 0.4908


testing with up sampling
================================================================================
TEST RESULTS FOR
MultinomialNB(alpha=0.1, class_prior=None, fit_prior=False)
================================================================================
             precision    recall  f1-score   support

    AGAINST     0.2632    0.2632    0.2632        19
      FAVOR     0.6202    0.7770    0.6898       973
       NONE     0.8739    0.7659    0.8164      1991

avg / total     0.7873    0.7663    0.7716      2983

Test macro F-score: 0.5898
time =  132.183230877