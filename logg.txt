25 januar:
- Kjører exhaustive grid search for classifierne SVC og multinomialNB. Har allerede kjørt for linearSVC, dette tok 5.5
timer, men virker til å faktisk finne beste parametrene. F-score ligger på 52.12 som beste baseline resultat så langt.
Tenkte å gjøre dette for å ha en baseline med de tre classifierne. Planen var å lagre resultatene i
System/TextFiles/baseline_results.txt og tilhørende beste parametre i System/TextFiles/baseline_parameter.txt.
Resultatene kommer fra baseline_system.py, men denne gangen har jeg inkludert "NONE" i f-score, uten at jeg vet helt hva
det utgjør i forhold til resultatene.

26. januar:
- Fortsatt kjører for å finne parametre til SVC. Ble ferdig, men fikk ikke resultater pga maccen gikk i dvale. Tok rolig
25 timer. Har ellers begynt å skrive på rapporten til SemEval 2016. Bare skrevet stikk-setninger for å få noe ned på
"papiret". Dette ligger på sharelatex.
TULLA. FIkk ut parametre allikevel :D Lagrer dem i baseline_parameter.txt.
Lagrer resultatet etter å ha kjørt med parametre i baseline_results.txt. Det jeg har jobbet med har ligget i
baseline branchen. Merger dette inn i master.


28. januar:
- Snakket med Erwin om hva vi gjorde, kunne gjort, hva vi skal og planen videre. Alt ligger på wiki-siden. Kort sagt
blir det å jobbe mot paper til 26. februar og samtidig jobbe med skeptical science data. Vi endte på 10. (av 19) plass
i SemEval konkurranse *klapp klapp*.

29. januar:
- Inkluder dummy classifiers med "stratified": generates predictions by respecting the training set’s class distribution
og "most_frequent": classen som er mest representert blir alltid valgt. Resultatene lagt inn baseline_results.txt.
Viste seg at most_frequent ikke ble så bra allikevel. Beste res er med SVM og Linear SVM (52 %). Time to beat that..
