using down sampling
using up sampling
================================================================================
LinearSVC(C=1.178, class_weight=None, dual=True, fit_intercept=True,
     intercept_scaling=1, loss='squared_hinge', max_iter=1000,
     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
     verbose=0)
================================================================================
             precision    recall  f1-score   support

    AGAINST     0.8675    0.8780    0.8727        82
      FAVOR     0.7124    0.6804    0.6960      1023
       NONE     0.7462    0.7729    0.7593      1255

avg / total     0.7357    0.7364    0.7358      2360

macro-average of F-score(FAVOR), F-score(AGAINST) and F-score(NONE): 0.7760

================================================================================
Validation score
================================================================================
             precision    recall  f1-score   support

    AGAINST     1.0000    0.0588    0.1111        17
      FAVOR     0.7015    0.5895    0.6406       877
       NONE     0.8107    0.8812    0.8445      1793

avg / total     0.7762    0.7808    0.7733      2687

Validation macro F-score: 0.5321


================================================================================
TEST RESULTS FOR
LinearSVC(C=1.178, class_weight=None, dual=True, fit_intercept=True,
     intercept_scaling=1, loss='squared_hinge', max_iter=1000,
     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
     verbose=0)
================================================================================
             precision    recall  f1-score   support

    AGAINST     0.5000    0.2105    0.2963        19
      FAVOR     0.6365    0.7163    0.6741       973
       NONE     0.8500    0.8026    0.8256      1991

avg / total     0.7781    0.7707    0.7728      2983

Test macro F-score: 0.5987
time =  119.126997948



using down sampling
using up sampling
================================================================================
MultinomialNB(alpha=0.1, class_prior=None, fit_prior=False)
================================================================================
             precision    recall  f1-score   support

    AGAINST     0.9600    0.8780    0.9172        82
      FAVOR     0.6636    0.7830    0.7184      1023
       NONE     0.7922    0.6805    0.7321      1255

avg / total     0.7423    0.7318    0.7326      2360

macro-average of F-score(FAVOR), F-score(AGAINST) and F-score(NONE): 0.7892

================================================================================
Validation score
================================================================================
             precision    recall  f1-score   support

    AGAINST     0.0000    0.0000    0.0000        17
      FAVOR     0.6162    0.7047    0.6574       877
       NONE     0.8414    0.7903    0.8151      1793

avg / total     0.7626    0.7574    0.7585      2687

Validation macro F-score: 0.4908


using down sampling
================================================================================
LinearSVC(C=1.178, class_weight=None, dual=True, fit_intercept=True,
     intercept_scaling=1, loss='squared_hinge', max_iter=1000,
     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
     verbose=0)
================================================================================
             precision    recall  f1-score   support

    AGAINST     0.2308    0.0732    0.1111        41
      FAVOR     0.6944    0.6774    0.6858      1023
       NONE     0.7355    0.7665    0.7507      1255

avg / total     0.7084    0.7150    0.7108      2319

macro-average of F-score(FAVOR), F-score(AGAINST) and F-score(NONE): 0.5159

================================================================================
Validation score
================================================================================
             precision    recall  f1-score   support

    AGAINST     1.0000    0.0588    0.1111        17
      FAVOR     0.7015    0.5895    0.6406       877
       NONE     0.8107    0.8812    0.8445      1793

avg / total     0.7762    0.7808    0.7733      2687

Validation macro F-score: 0.5321


testing with down sampling
================================================================================
TEST RESULTS FOR
LinearSVC(C=1.178, class_weight=None, dual=True, fit_intercept=True,
     intercept_scaling=1, loss='squared_hinge', max_iter=1000,
     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
     verbose=0)
================================================================================
             precision    recall  f1-score   support

    AGAINST     0.5000    0.2105    0.2963        19
      FAVOR     0.6365    0.7163    0.6741       973
       NONE     0.8500    0.8026    0.8256      1991

avg / total     0.7781    0.7707    0.7728      2983

Test macro F-score: 0.5987
time =  161.145936012



using up sampling
================================================================================
LinearSVC(C=1.178, class_weight=None, dual=True, fit_intercept=True,
     intercept_scaling=1, loss='squared_hinge', max_iter=1000,
     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
     verbose=0)
================================================================================
             precision    recall  f1-score   support

    AGAINST     0.9863    0.8780    0.9290        82
      FAVOR     0.6654    0.5850    0.6226      2046
       NONE     0.8078    0.8573    0.8318      4183

avg / total     0.7640    0.7693    0.7653      6311

macro-average of F-score(FAVOR), F-score(AGAINST) and F-score(NONE): 0.7945

================================================================================
Validation score
================================================================================
             precision    recall  f1-score   support

    AGAINST     1.0000    0.0588    0.1111        17
      FAVOR     0.7015    0.5895    0.6406       877
       NONE     0.8107    0.8812    0.8445      1793

avg / total     0.7762    0.7808    0.7733      2687

Validation macro F-score: 0.5321


testing with up sampling
================================================================================
TEST RESULTS FOR
LinearSVC(C=1.178, class_weight=None, dual=True, fit_intercept=True,
     intercept_scaling=1, loss='squared_hinge', max_iter=1000,
     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
     verbose=0)
================================================================================
             precision    recall  f1-score   support

    AGAINST     0.5000    0.1053    0.1739        19
      FAVOR     0.7108    0.6238    0.6645       973
       NONE     0.8245    0.8800    0.8513      1991

avg / total     0.7853    0.7915    0.7861      2983

Test macro F-score: 0.5632
time =  317.268763065








#######################################
Multinomial NB
#######################################

testing with down sampling
testing with up sampling
================================================================================
TEST RESULTS FOR
MultinomialNB(alpha=0.1, class_prior=None, fit_prior=False)
================================================================================
             precision    recall  f1-score   support

    AGAINST     0.3333    0.3158    0.3243        19
      FAVOR     0.5935    0.7698    0.6702       973
       NONE     0.8673    0.7418    0.7997      1991

avg / total     0.7746    0.7482    0.7544      2983

Test macro F-score: 0.5981
time =  92.7744238377

using down sampling
================================================================================
MultinomialNB(alpha=0.1, class_prior=None, fit_prior=False)
================================================================================
             precision    recall  f1-score   support

    AGAINST     0.0000    0.0000    0.0000        41
      FAVOR     0.6553    0.7713    0.7086      1023
       NONE     0.7731    0.6869    0.7274      1255

avg / total     0.7075    0.7119    0.7062      2319

macro-average of F-score(FAVOR), F-score(AGAINST) and F-score(NONE): 0.4787

================================================================================
Validation score
================================================================================
             precision    recall  f1-score   support

    AGAINST     0.0000    0.0000    0.0000        17
      FAVOR     0.6162    0.7047    0.6574       877
       NONE     0.8414    0.7903    0.8151      1793

avg / total     0.7626    0.7574    0.7585      2687

Validation macro F-score: 0.4908


testing with down sampling
================================================================================
TEST RESULTS FOR
MultinomialNB(alpha=0.1, class_prior=None, fit_prior=False)
================================================================================
             precision    recall  f1-score   support

    AGAINST     0.4000    0.1053    0.1667        19
      FAVOR     0.5886    0.7749    0.6690       973
       NONE     0.8674    0.7393    0.7983      1991

avg / total     0.7735    0.7469    0.7521      2983

Test macro F-score: 0.5447
time =  98.0226840973

using nothing
using up sampling
================================================================================
MultinomialNB(alpha=0.1, class_prior=None, fit_prior=False)
================================================================================
             precision    recall  f1-score   support

    AGAINST     0.8889    0.8780    0.8834        82
      FAVOR     0.5901    0.7522    0.6614      2046
       NONE     0.8589    0.7437    0.7972      4183

avg / total     0.7722    0.7482    0.7543      6311

macro-average of F-score(FAVOR), F-score(AGAINST) and F-score(NONE): 0.7807

================================================================================
Validation score
================================================================================
             precision    recall  f1-score   support

    AGAINST     0.0000    0.0000    0.0000        17
      FAVOR     0.6162    0.7047    0.6574       877
       NONE     0.8414    0.7903    0.8151      1793

avg / total     0.7626    0.7574    0.7585      2687

Validation macro F-score: 0.4908


testing with up sampling
================================================================================
TEST RESULTS FOR
MultinomialNB(alpha=0.1, class_prior=None, fit_prior=False)
================================================================================
             precision    recall  f1-score   support

    AGAINST     0.2632    0.2632    0.2632        19
      FAVOR     0.6202    0.7770    0.6898       973
       NONE     0.8739    0.7659    0.8164      1991

avg / total     0.7873    0.7663    0.7716      2983

Test macro F-score: 0.5898
time =  132.183230877