########################################################################################
MultinomialNB(alpha=0.1, class_prior=None, fit_prior=False)
########################################################################################
================================================================================
Cross validated train score
================================================================================
             precision    recall  f1-score   support

    AGAINST     0.1935    0.1463    0.1667        41
      FAVOR     0.5697    0.7634    0.6525      2046
       NONE     0.8559    0.7155    0.7794      4183

avg / total     0.7581    0.7274    0.7340      6270

macro-average of F-score(FAVOR), F-score(AGAINST) and F-score (NONE): 0.5329


Start validation. Time used: 1.3 minutes
================================================================================
Validation score
================================================================================
             precision    recall  f1-score   support

    AGAINST     0.2143    0.1765    0.1935        17
      FAVOR     0.5755    0.7868    0.6647       877
       NONE     0.8731    0.7178    0.7879      1793

avg / total     0.7718    0.7369    0.7439      2687

Validation macro F-score: 0.5487


================================================================================
TEST RESULTS FOR
MultinomialNB(alpha=0.1, class_prior=None, fit_prior=False)
================================================================================
             precision    recall  f1-score   support

    AGAINST     0.3125    0.2632    0.2857        19
      FAVOR     0.5958    0.7862    0.6779       973
       NONE     0.8752    0.7398    0.8019      1991

avg / total     0.7805    0.7519    0.7581      2983

Test macro F-score: 0.5885
Time used 1.9 in minutes


########################################################################################
BernoulliNB(alpha=0.1, binarize=0.0, class_prior=None, fit_prior=True)
########################################################################################
================================================================================
Cross validated train score
================================================================================
             precision    recall  f1-score   support

    AGAINST     0.1385    0.2195    0.1698        41
      FAVOR     0.5991    0.7458    0.6645      2046
       NONE     0.8546    0.7473    0.7973      4183

avg / total     0.7665    0.7434    0.7499      6270

macro-average of F-score(FAVOR), F-score(AGAINST) and F-score(NONE): 0.5439

================================================================================
Validation score
================================================================================
             precision    recall  f1-score   support

    AGAINST     0.0500    0.0588    0.0541        17
      FAVOR     0.6277    0.7035    0.6634       877
       NONE     0.8450    0.7936    0.8185      1793

avg / total     0.7690    0.7596    0.7631      2687

Validation macro F-score: 0.5120


================================================================================
TEST RESULTS FOR
BernoulliNB(alpha=0.1, binarize=0.0, class_prior=None, fit_prior=True)
================================================================================
             precision    recall  f1-score   support

    AGAINST     0.0000    0.0000    0.0000        19
      FAVOR     0.6721    0.6763    0.6742       973
       NONE     0.8377    0.8428    0.8403      1991

avg / total     0.7784    0.7831    0.7807      2983

Test macro F-score: 0.5048
time =  190.241985083




########################################################################################
LinearSVC(C=5.2, class_weight=None, dual=True, fit_intercept=True,
     intercept_scaling=1, loss='squared_hinge', max_iter=1000,
     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
     verbose=0)
########################################################################################
================================================================================
Cross validated train score
================================================================================
             precision    recall  f1-score   support

    AGAINST     0.5000    0.0244    0.0465        41
      FAVOR     0.6561    0.6647    0.6604      2046
       NONE     0.8308    0.8331    0.8319      4183

avg / total     0.7716    0.7729    0.7708      6270

macro-average of F-score(FAVOR), F-score(AGAINST) and F-score(NONE): 0.5129

================================================================================
Validation score
================================================================================
/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
             precision    recall  f1-score   support

    AGAINST     0.0000    0.0000    0.0000        17
      FAVOR     0.6790    0.6682    0.6736       877
       NONE     0.8366    0.8511    0.8438      1793

avg / total     0.7799    0.7860    0.7829      2687

/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
Validation macro F-score: 0.5058


================================================================================
TEST RESULTS FOR
LinearSVC(C=5.2, class_weight=None, dual=True, fit_intercept=True,
     intercept_scaling=1, loss='squared_hinge', max_iter=1000,
     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
     verbose=0)
================================================================================
             precision    recall  f1-score   support

    AGAINST     0.4000    0.1053    0.1667        19
      FAVOR     0.6797    0.6259    0.6517       973
       NONE     0.8213    0.8589    0.8397      1991

avg / total     0.7724    0.7781    0.7741      2983

Test macro F-score: 0.5527
time =  139.873800039




########################################################################################
SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,
       eta0=0.0, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=1,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
########################################################################################

Cross validated train score
================================================================================
             precision    recall  f1-score   support

    AGAINST     0.1364    0.0732    0.0952        41
      FAVOR     0.6291    0.5860    0.6068      2046
       NONE     0.8010    0.8315    0.8160      4183

avg / total     0.7406    0.7464    0.7430      6270

macro-average of F-score(FAVOR), F-score(AGAINST) and F-score(NONE): 0.5060

================================================================================
Validation score
================================================================================
             precision    recall  f1-score   support

    AGAINST     0.1875    0.1765    0.1818        17
      FAVOR     0.6574    0.6716    0.6644       877
       NONE     0.8383    0.8299    0.8341      1793

avg / total     0.7751    0.7741    0.7746      2687

Validation macro F-score: 0.5601


================================================================================
TEST RESULTS FOR
SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,
       eta0=0.0, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=1,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
================================================================================
             precision    recall  f1-score   support

    AGAINST     0.0556    0.0526    0.0541        19
      FAVOR     0.6331    0.6136    0.6232       973
       NONE     0.8136    0.8262    0.8198      1991

avg / total     0.7499    0.7519    0.7508      2983

Test macro F-score: 0.4990
time =  221.301043987
